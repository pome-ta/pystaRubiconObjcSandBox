# ğŸ“ 2024/05/06


## `block` å†…ã®å‡¦ç†

ctypes ã§ã“ã­ã“ã­ã™ã‚‹ã‹ã‚‰ã€ãƒ¡ãƒ¢

```.py
ctypes.cast(outputData, ctypes.POINTER(AudioBufferList))

'''
['__bool__', '__class__', '__ctypes_from_outparam__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_b_base_', '_b_needsfree_', '_objects', '_type_', 'contents']
'''


ctypes.cast(outputData, ctypes.POINTER(AudioBufferList)).contents

'''
['__class__', '__ctypes_from_outparam__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_b_base_', '_b_needsfree_', '_fields_', '_objects', 'mBuffers', 'mNumberBuffers']
'''

```


```.py

for buffer in abl.mBuffers:
  print(buffer)
  print(dir(buffer))


'''
<__main__.AudioBuffer object at 0x118ebdfc0>
['__class__', '__ctypes_from_outparam__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_b_base_', '_b_needsfree_', '_fields_', '_objects', 'mData', 'mDataByteSize', 'mNumberChannels']
'''

```

## `UnsafeMutableAudioBufferListPointer` ã¨`UnsafeMutableBufferPointer`

ãªã‹ãªã‹ã€ã‚ã‹ã‚‰ã‚“ã®ã§ãƒ¡ãƒ¢ã—ãªãŒã‚‰æ•´ç†ã—ã¦ã„ã


```.swift
lazy var sourceNode = AVAudioSourceNode { [self] (_, _, frameCount, audioBufferList) -> OSStatus in
    // `AudioBufferList` ã®ã€`mBuffers` é…åˆ—è¦ç´ ã‚’æ“ä½œã§ãã‚‹ã‚ˆã†ãªå½¢å¼ã«ãªã‚‹ï¼Ÿ
    let abl = UnsafeMutableAudioBufferListPointer(audioBufferList)
    // `frameCount` = `1024` ã¨ã‹
    for frame in 0..<Int(frameCount) {
        let sampleVal: Float = sin(AudioEngeneWaveGenerator.toneA * 2.0 * Float(Double.pi) * self.time)
        self.time += self.deltaTime
        // `frame` åˆ†ã®æ™‚é–“å‡¦ç†ã‚’ã—ã¦ã‹ã‚‰å‘¼ã³å‡ºã—ã‚’ã—ã¦ã„ã‚‹
        // channel ã¨ã—ã¦ã¯`1` ãªã®ã§1å›ã®å‡¦ç†
        for buffer in abl {
            // ä¸­èº«ãŒ`Float` ã¨ãªã‚‹ã£ã¦ã“ã¨ï¼Ÿå½¢ã¨ã—ã¦ã¯é…åˆ—ã¿ãŸã„ãªï¼Ÿ
            // ã“ã“ã§ã‚­ãƒ£ã‚¹ãƒˆã‹
            let buf: UnsafeMutableBufferPointer<Float> = UnsafeMutableBufferPointer(buffer)
            buf[frame] = sampleVal
        }
    }
    return noErr
}
```








[UnsafeMutablePointer | Apple Developer Documentation](https://developer.apple.com/documentation/swift/unsafemutablepointer)





# ğŸ“ 2024/05/04


`load_library` ã§framework å–ã£ã¦ãã‚‹ã‹ï¼Ÿã¨æ€ã£ã¦ã‚‚
ã‚ã¾ã‚Šæ„å‘³ãªã•ãã†

æ§‹é€ ä½“ã‚’è‡ªåˆ†ã§ä½œã‚‹ãªã®ã‹ãªï¼Ÿ

[Core Audio | Apple Developer Documentation](https://developer.apple.com/documentation/coreaudio?language=objc)


`.locatble` ? ã¿ãŸã„ãªã®ã‚’å–ã£ã¦ãã‚‹ã®ã‹ãªï¼Ÿ


## æ§‹é€ ä½“


[AudioBuffer | Apple Developer Documentation](https://developer.apple.com/documentation/coreaudiotypes/audiobuffer?language=objc)


An audio buffer holds a single buffer of audio data in its mData field. The buffer can represent two types of audio:

- A single, monophonic, noninterleaved channel of audio
- Interleaved audio with the number of channels set by the mNumberChannels field

ã‚ªãƒ¼ãƒ†ã‚™ã‚£ã‚ªãƒã‚™ãƒƒãƒ•ã‚¡ã¯ã€mDataãƒ•ã‚£ãƒ¼ãƒ«ãƒˆã‚™ã«ã‚ªãƒ¼ãƒ†ã‚™ã‚£ã‚ªãƒ†ã‚™ãƒ¼ã‚¿ã®å˜ä¸€ã®ãƒã‚™ãƒƒãƒ•ã‚¡ã‚’ä¿æŒã—ã¾ã™ã€‚ãƒã‚™ãƒƒãƒ•ã‚¡ã¯2ç¨®é¡ã®ã‚ªãƒ¼ãƒ†ã‚™ã‚£ã‚ªã‚’è¡¨ã™ã“ã¨ã‹ã‚™ã¦ã‚™ãã¾ã™ã€‚

- ã‚ªãƒ¼ãƒ†ã‚™ã‚£ã‚ªã®å˜ä¸€ã€ãƒ¢ãƒãƒ•ã‚©ãƒ‹ãƒƒã‚¯ã€éã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ•ã‚™ãƒãƒ£ãƒ³ãƒãƒ«
- mNumberChannelsãƒ•ã‚£ãƒ¼ãƒ«ãƒˆã‚™ã¦ã‚™è¨­å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ•ã‚™ã‚ªãƒ¼ãƒ†ã‚™ã‚£ã‚ª


[Core Audio ãã®1 AudioBufferã¨AudioBufferList | objective-audio](kVariableLengthArray)


# ğŸ“ 2024/05/03

[GitHub - TokyoYoshida/CoreAudioExamples](https://github.com/TokyoYoshida/CoreAudioExamples)




# ğŸ“ 2024/05/02

[Building a Signal Generator | Apple Developer Documentation](https://developer.apple.com/documentation/avfaudio/audio_engine/building_a_signal_generator)


```.swift
let srcNode = AVAudioSourceNode { _, _, frameCount, audioBufferList -> OSStatus in
    let ablPointer = UnsafeMutableAudioBufferListPointer(audioBufferList)
    for frame in 0..<Int(frameCount) {
        // Get the signal value for this frame at time.
        let value = signal(currentPhase) * amplitude
        // Advance the phase for the next frame.
        currentPhase += phaseIncrement
        if currentPhase >= twoPi {
            currentPhase -= twoPi
        }
        if currentPhase < 0.0 {
            currentPhase += twoPi
        }
        // Set the same value on all channels (due to the inputFormat, there's only one channel though).
        for buffer in ablPointer {
            let buf: UnsafeMutableBufferPointer<Float> = UnsafeMutableBufferPointer(buffer)
            buf[frame] = value
        }
    }
    return noErr
}
```

# ğŸ“ 2024/05/01

[swift3ã¦ã‚™CoreAudioã‚’ä½¿ã† å†ç”Ÿç·¨ - Pebble Coding](https://pebble8888.hatenablog.com/entry/2015/12/05/192914)

[Building a Signal Generator | Apple Developer Documentation](https://developer.apple.com/documentation/avfaudio/audio_engine/building_a_signal_generator)

# ğŸ“ 2024/03/30

[Core Audio ãã®ï¼‘ AudioBufferã¨AudioBufferList | objective-audio](https://objective-audio.jp/2008/03/22/core-audio-audiobufferaudiobuf/)
